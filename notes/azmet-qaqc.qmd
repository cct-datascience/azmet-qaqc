---
title: "QA by Forecasting"
format: 
  html:
    toc: true
    number-sections: true
editor: visual
bibliography: references.bib
---

```{r setup}
#| echo: true
#| code-fold: false
#| warning: false
#| message: false

# remotes::install_github("cct-datascience/azmetr")
library(azmetr)
library(tsibble)
library(tidyverse)
library(lubridate)
library(feasts)
library(fable)
library(here)
```

# Problem Definition

We want to use forecasts to do quality assurance of AZMet weather data.
Use the existing timeseries available from the API (and possibly also historical data not on the API) to forecast the current day's (or hour's) data with prediction interval(s).
Data that falls outside of those prediction interval(s) will get flagged as extreme values and possibly interpolated.
Variables that need QA include:

-   precipitation
-   air temperature
-   soil temperature
-   solar radiation
-   wind speed
-   humidity

Other variables are (probably?) derived

To see a rough "sketch" of the QA workflow, skip to @sec-qa-workflow.

# Gathering Information

Load data

```{r}
tar_load(daily)
```


Any rows marked as needing review?

```{r}
daily_ts |> filter(meta_needs_review != 0)
```

Check extreme values:

```{r}
daily_ts |> filter(temp_air_meanC > 200)
```

Looks like historic data uses 999 for NA probably.
I'll set those to `NA`

```{r}
daily_ts <- daily_ts |> 
  mutate(across(where(is.numeric), \(x) if_else(x == 999, NA_real_, x)))
```

Any gaps in the data?

```{r}
daily_ts |> scan_gaps()
```

yes, let's make them explicit NAs

```{r}
daily_ts <- fill_gaps(daily_ts, .full = TRUE)
```

Check that gaps were made explicit:

```{r}
#| code-fold: true
daily_ts |> 
  filter(meta_station_id %in% c("az23", "az14"))|>
  filter(year(datetime) > 2018) |> 
  ggplot(aes(x = datetime, y = sol_rad_total)) +
  geom_line(na.rm = TRUE, size = 0.1) +
  geom_point(na.rm = TRUE, size = 0.2) +
  facet_wrap(~meta_station_id)
```

# Preliminary (exploratory) analysis

I'll start by looking at a subset of sites just to make visualization easier.

```{r}
daily_ts_sub <-
  daily_ts |> 
  filter(meta_station_name %in% c("Aguila", "Harquahala", "Tucson", "Maricopa"))
```

Is there missing data?

```{r}
#| fig-height: 10
#| fig-width: 10

daily_ts_sub |> 
  as_tibble() |>
  group_by(meta_station_id, meta_station_name) |> 
  summarize(across(everything(), ~sum(is.na(.))))

```

Some variables are incomplete or have a short time gap.
This may make forecasting difficult.

## Mean Air Temp

```{r}
daily_ts_sub |> 
  autoplot(temp_air_meanC) +
  labs(title = "Mean Air Temp (ºC)")
```

Seasonality

```{r}
daily_ts_sub |> gg_season(temp_air_meanC) + labs(title = "Mean Air Temp (ºC)")
```

Autocorrelation

```{r}
daily_ts_sub |>
  ACF(temp_air_meanC, lag_max = 180) |> 
  autoplot()
```

## Solar Radiation

```{r}
daily_ts_sub |> autoplot(sol_rad_total) + labs(title = "Total Solar Radiation")
```

Seasonality

```{r}
daily_ts_sub |> gg_season(sol_rad_total) + labs(title = "Total Solar Radiation")
```

Definitely some weird zeroes.
Maybe a super cloudy day, but probably errors.

```{r}
#| code-fold: true
daily_ts |> 
  filter(sol_rad_total < 1 & !is.na(sol_rad_total)) |> 
  select(datetime, sol_rad_total, meta_station_id, meta_needs_review) |> 
  arrange(sol_rad_total)
```

Autocorrelation

```{r}
daily_ts_sub |>
  ACF(sol_rad_total, lag_max = 180) |> 
  autoplot()
```

## Precipitation

```{r}
daily_ts_sub |> autoplot(precip_total_mm) + labs(title = "Precip (mm)")
```

Seasonality

```{r}
daily_ts_sub |> gg_season(precip_total_mm) + labs(title = "Precip (mm)")
```

Autocorrelation

```{r}
daily_ts_sub |>
  ACF(precip_total_mm, lag_max = 180) |> 
  autoplot()
```

# QA workflow {#sec-qa-workflow}

0.  Choose and validate models for each variable (see @sec-forecasting)

1.  Fit model to all data but most recent day

```{r}
#| warning: false
#split data into historical...
sol_hist <- 
  daily_ts_sub |> 
  select(sol_rad_total) |> 
  filter(datetime < max(datetime))

#and most recent data...
sol_new <-
  daily_ts_sub |> 
  select(sol_rad_total) |> 
   # make an outlier for testing
  mutate(sol_rad_total = if_else(meta_station_id == "az01", 5, sol_rad_total)) |> 
  filter(datetime == max(datetime))

#fit model(s) for variables
sol_fit <- 
  sol_hist |> 
  model(sol = SNAIVE(sol_rad_total ~ lag("1 year"))) #seasonal naieve model, for example

```

2.  Forecast to new data

```{r}
#| warning: false
sol_fc <- 
  sol_fit |> 
  forecast(sol_new, bootstrap = TRUE)
```

```{r}
autoplot(
  sol_fc, 
  sol_hist |> 
    filter(datetime > ymd("2022-09-01")),
  level = c(95, 99)
) +
  geom_point(data = sol_new, aes(y = sol_rad_total), shape = "triangle", size = 0.7, color = "red") +
  labs(caption= "blue dot = forecast point, red triangle = actual data")
```

3.  Check if data is inside prediction intervals

```{r}
flags <-
  left_join(as_tibble(sol_new), as_tibble(sol_fc |> hilo(c(95, 99)) |> select(-sol_rad_total))) |> 
  mutate(
    outlier = if_else(sol_rad_total < `95%`$lower | sol_rad_total > `95%`$upper,
                      "sol_rad_total",
                      NA_character_),
    extreme = if_else(sol_rad_total < `99%`$lower | sol_rad_total > `99%`$upper,
                      "sol_rad_total",
                      NA_character_)
         ) |> 
  select(meta_station_id, meta_station_name, datetime, forecast = .mean, outlier, extreme)
flags
```

4.  Create report with flags and imputed (forecast) data for extreme values

```{r}
left_join(daily_ts_sub |> as_tibble(), flags, by = c("datetime", "meta_station_id")) |> 
  arrange(desc(datetime)) |> 
  select(datetime, meta_station_id, sol_rad_total, outlier, extreme, forecast)
```

# Learning about forecasting {#sec-forecasting}

## Timeseries decomposition

Timeseries decomposition doesn't work when there is missing data.
There are `NA`s for Harquahala and Bowie stations, so I guess I'll have to omit those until I figure out how to do this with missing data.

```{r}
daily_ts_sub |> filter(is.na(sol_rad_total))
```

```{r}
dcmp <- 
  daily_ts_sub |> 
  filter(meta_station_id == first(meta_station_id)) |> #just use one station for now
  model(stl = STL(sol_rad_total ~ season("1_year"))) |> 
  filter(meta_station_id %in% c("az01", "az06"))
components(dcmp)
```

```{r}
components(dcmp) |>
  as_tsibble() |>
  autoplot(sol_rad_total, color = "grey") +
  facet_wrap(~meta_station_id + meta_station_name, ncol = 1) +
  geom_line(aes(y = trend, color = "trend")) 

components(dcmp) |> autoplot()
```

## Timeseries Features

Similar to `summarise()`

```{r}
daily_ts_sub |> 
  features(sol_rad_total, list(
    mean = \(x) mean(x, na.rm = TRUE)
  )) |> arrange(mean)
```

But for specialized functions, can take seasonality into account.
For example, autocorrelation:

```{r}
daily_ts_sub |>
  features(sol_rad_total, feat_acf, .period = "1 year")
```

-   ACF1 (first autocorrelation coefficient) is high, which I think means there is unaccounted-for variation
-   ACF10 (sum of squares of first 10 autocorrelation coefficients??)

Or seasonal timeseries decomposition

```{r}
daily_ts_sub |> 
  features(sol_rad_total, feat_stl, .period = "1 year")

```

-   Trend strength is low (makes sense)
-   seasonal strength is high (makes sense)
-   the peak (most hours of sun) is on DOY 171 in most sites (makes sense)
-   the trough (least hours of sun) is on DOY 350 in most sites (make sense)

## Timeseries Models

Train a model.
IN this case, a simple timeseries linear model (TSLM)

```{r}
fit_tslm <- daily_ts_sub |> 
  model(TSLM(sol_rad_total~ trend())) 
fit_tslm
```

A slightly fancier model: seasonal naïve

```{r}
fit_snaive <- daily_ts_sub |> 
  model(SNAIVE(sol_rad_total ~ lag("1 year")))
fit_snaive
```

A model including timeseries decomposition:

```{r}
fit_dcmp <-
  daily_ts_sub |> 
  model(stlf = decomposition_model(
    STL(sol_rad_total ~ season(period = "1 year")),
    NAIVE(season_adjust)
  ))
```

## Forecasting methods

Produce forecasts

```{r}
fit_tslm |> forecast(h = "3 months")
fit_tslm |> 
  forecast(h = "3 months") |> 
  filter(meta_station_name == "Tucson") |> 
  autoplot(daily_ts_sub |> filter(year(datetime)>2021))
```

A very bad forecast because there is no trend here.

What about "seasonal naïve"

```{r}
fit_snaive |> 
  forecast(h = "1 month") |> 
  filter(meta_station_name == "Tucson") |> 
  autoplot(daily_ts_sub |> filter(year(datetime)>2021), level = c(95, 99))
```

OOf, those prediction inteverals are WIDE.

Check residuals

```{r}
fit_snaive |> filter(meta_station_id == "az01") |> gg_tsresiduals()
```
Residuals are autocorelated (bad) and not normal (bad).

Could use bootstrapped residuals.

```{r}
fc <- fit_snaive |> forecast(h = "1 month", bootstrap = TRUE)
fc
```

```{r}
fc |> 
  filter(meta_station_name == "Tucson") |> 
  autoplot(daily_ts_sub |> filter(year(datetime)>2021))
```

Can do forecasting after decomposition

```{r}

fit_dcmp |> 
  forecast(h = "1 month") |> 
  filter(meta_station_id ==  "az01") |> 
  autoplot(daily_ts_sub |> filter(year(datetime)>2021), level = c(95, 99))
```

```{r}
fit_dcmp |> filter(meta_station_id == "az01") |> gg_tsresiduals()
```

Better??

Let's find out

## Model/forecast diagnostics

```{r}
sol_rad_train <- 
  daily_ts_sub |> 
  filter(meta_station_id == "az01") |> 
  filter(year(datetime) < 2022) |> 
  select(sol_rad_total)

sol_rad_test <- 
  daily_ts_sub |> 
  filter(meta_station_id == "az01") |> 
  filter(year(datetime) >= 2022) |> 
  select(sol_rad_total)

fit_compare <- 
  sol_rad_train |> 
  model(
    mean = MEAN(sol_rad_total),
    naive = NAIVE(sol_rad_total),
    snaive = SNAIVE(sol_rad_total ~ lag("1 year")),
    drift = RW(sol_rad_total ~ drift()),
    stlf = decomposition_model(
      STL(sol_rad_total ~ season(period = "1 year")),
      NAIVE(season_adjust)
    ),
    arima = ARIMA(sol_rad_total)
  )

fc <- fit_compare |> forecast(sol_rad_test)
fc |> 
  autoplot(bind_rows(sol_rad_train, sol_rad_test) |> filter(year(datetime)>=2021), level = NULL)
accuracy(fc, sol_rad_test)

#winkler score evaluates prediction interval accuracy

accuracy(fc, sol_rad_test, list(winkler = winkler_score), level = 80)
```

Best method here is seasonal naive.
I guess this isn't terribly surprising for these type of data?
I feel like it should be *smoother* though.

```{r}
fc |> 
  filter(.model %in% c("arima", "snaive")) |> 
  autoplot(sol_rad_train |> filter(year(datetime)>=2021), level = c(95, 99)) +
  geom_line(data = sol_rad_test, aes(y = sol_rad_total), alpha = 0.3, linetype = 2)

```

Surprised that ARIMA did poorly.
Maybe I'm not understanding it well?
Maybe I have to specify seasonality since I know it?

```{r}
fit_arima <- sol_rad_train |> 
  model(ARIMA(sol_rad_total))
report(fit_arima)
```

```{r}
sol_rad_train |> 
  gg_tsdisplay(difference(sol_rad_total, 365), plot_type = "partial", lag = 365*2)
```

Strong spike at lag 1 suggests non-seasonal MA(1).
Strong spike at a year ago indicates seasonal MA(1) component.
So ARIMA(0,1,1)(0,1,1)~12~ (first difference, non-seasonal MA(2), seasonal MA(1)

p = order of the autoregressive part

d = degree of first differencing involved

q = order of the moving average part

```{r}
fit_arima2 <- sol_rad_train |> 
  model(
    # arima011011 = ARIMA(sol_rad_total ~ pdq(0,1,1) + PDQ(0,1,1, period = "1 year")),
    # arima111011 = ARIMA(sol_rad_total ~ pdq(1,1,1) + PDQ(0,1,1, period = "1 year")),
    # auto = ARIMA(sol_rad_total ~ pdq(0:5, 0:2, 0:5) + PDQ(0:2, 0:1, 0:2, period = "1 year"), stepwise = FALSE, approximation = FALSE)
  )
#stepwise = FALSE and approximation = FALSE makes R work harder to find a good solution
```

```{r}
fit_arima2 |> pivot_longer(everything(), names_to = "Model name", values_to = "Orders")
glance(fit_arima2) |> arrange(AIC) |> select(.model:BIC)

accuracy(fit_arima2 |> forecast(sol_rad_test), sol_rad_test)
fit_arima2 |> select(auto) |> forecast(sol_rad_test) |> autoplot()
```

It's getting seasonality wrong.
I think the \[7\] means 7 days.
It should be a seasonality of 365!

```{r}
fit_arima2 |> select(auto) |> forecast() |> autoplot(sol_rad_test)
fit_arima2 |> select(auto) |> gg_tsresiduals()
fit_arima2 |> select(arima111011) |> gg_tsresiduals()
fit_arima2 |> select(arima011011) |> gg_tsresiduals()
```

big acf 2, resids are leptokurtic

```{r}
sol_rad_train |> 
  model(
    auto_repl = ARIMA(sol_rad_total ~ 1 + pdq(1,0,1) + PDQ(1,0,0))
  )
```

How does it do on other variables?

```{r}
fit_temp <- 
  daily_ts_sub |> 
  model(
    auto = ARIMA(temp_air_meanC)
  )
fit_temp
```
