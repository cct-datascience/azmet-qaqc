---
title: "Report"
format: 
  html:
    code-fold: true
    toc: true
editor: visual
server: shiny
---

```{r}
#| include: false
#| context: setup
library(targets)
library(tidyverse)
library(fabletools)
library(lubridate)
library(pointblank)
library(arrow)
library(slider)
library(gt)
library(shinycssloaders)
tar_load(c(
  # fc_daily,
  db_daily,
  db_hourly,
  # forecast_qa_vars
))
#convert arrow connection to duckdb connection so pointblank can work on them
daily <-
  open_dataset(db_daily) #|> 
  # to_duckdb()
hourly <-
  open_dataset(db_hourly) |> 
  to_duckdb()
```

This report uses the `pointblank` package for displaying data validation results.
In the tables below the "STEP" column contains the name of the validation function, but you can mouse over it for a more human-readable description.
The UNITS column is how many rows were tested, PASS and FAIL columns show the number (upper) and fraction (lower) of rows that pass or fail the validation step.
The W S N column shows whether this step triggered a warning, a stop, or a notification.
The EXT column contains a blue CSV button to download ("EXTract") the failed rows for the validation for you to inspect.
Find more on the anatomy of this table in the `pointblank` [documentation](https://rich-iannone.github.io/pointblank/articles/VALID-I.html#a-simple-example-with-the-basics).

# Consistency checks

```{r}
#slider input might be better?
data_range <- daily |>
  pull(datetime, as_vector = TRUE) |> 
  range(na.rm = TRUE)
dateRangeInput(
  "daterange",
  "Date Range",
  min = data_range[1],
  max = data_range[2],
  start = data_range[2] - 14,
  end = data_range[2],
)
```

## Daily Data

```{r}
#| column: body-outset
gt_output(outputId = "check_daily")
```

## Hourly Data

```{r}
#| column: body-outset
gt_output(outputId = "check_hourly")
```

```{r}
#| context: server

al <- action_levels(warn_at = 1, stop_at = 0.1)


output$check_daily <-
  gt::render_gt({
    start <- input$daterange[1]
    end <- input$daterange[2]
    daily_check <-
      daily |>
      filter(datetime > start & datetime <= end) |>
      collect() |> 
      create_agent(
        # tbl_name = "Daily Data Consistency Checks",
        # label = "Consistency Checks",
        actions = al
      ) |>
      # Internal consistency checks from 'NWS (1994) TSP 88-21-R2':
      col_vals_gte(temp_air_meanC, vars(dwpt_mean), na_pass = TRUE) |>
      col_vals_lte(temp_air_minC, vars(temp_air_meanC), na_pass = TRUE) |>
      col_vals_lte(temp_air_meanC, vars(temp_air_maxC), na_pass = TRUE) |>
      col_vals_lte(wind_spd_mean_mps, vars(wind_spd_max_mps), na_pass = TRUE) |>
      col_vals_lte(temp_soil_10cm_meanC, vars(temp_soil_10cm_maxC), na_pass = TRUE) |>
      col_vals_lte(temp_soil_10cm_minC, vars(temp_soil_10cm_meanC), na_pass = TRUE) |>
      col_vals_lte(temp_soil_50cm_meanC, vars(temp_soil_50cm_maxC), na_pass = TRUE) |>
      col_vals_lte(temp_soil_50cm_minC, vars(temp_soil_50cm_meanC), na_pass = TRUE) |>
      col_vals_lte(relative_humidity_mean,
                   vars(relative_humidity_max),
                   na_pass = TRUE) |>
      col_vals_lte(relative_humidity_min,
                   vars(relative_humidity_mean),
                   na_pass = TRUE) |>

      #TODO calculate max sol radiation based on date and location and check for that
      # col_vals_lt(sol_rad_total, sol_rad_expected, preconditions = ~calc_sol(date))
      interrogate()
    get_agent_report(daily_check, title = "Daily Consistency Checks")
  })


output$check_hourly <-
  render_gt({
    start <- input$daterange[1]
    end <- input$daterange[2]
    hourly_check <-
      hourly |>
      filter(date_datetime > start & date_datetime <= end) |>
      collect() |> 
      create_agent(
        tbl_name = "Hourly measures",
        label = "Consistency Checks",
        actions = al
      ) |>
      # Internal consistency checks from 'NWS (1994) TSP 88-21-R2':
      col_vals_gte(temp_airC, vars(dwpt), na_pass = TRUE) |>
      col_vals_lte(wind_spd_mps, vars(wind_spd_max_mps), na_pass = TRUE) |>

      # Temporal consistency checks from 'NWS (1994) TSP 88-21-R2':
      col_vals_lt(
        temp_airC_delta,
        19.4,
        na_pass = TRUE,
        brief = "Expect that |∆`temp_airC`| < 19.4",
        preconditions = function(x) x |>
          group_by(meta_station_id) |>
          mutate(temp_airC_delta = abs(temp_airC - lag(temp_airC)),
                 .after = temp_airC) |>
          ungroup()
      ) |>
      col_vals_lt(
        relative_humidity_delta,
        50,
        na_pass = TRUE,
        brief = "Expect that |∆`relative_humidity`| < 50",
        preconditions = function(x) x |>
          group_by(meta_station_id) |>
          mutate(relative_humidity_delta = abs(relative_humidity - lag(relative_humidity)),
                 .after = relative_humidity) |>
          ungroup()
      ) |>
      col_vals_lt(
        wind_spd_mps_delta,
        10.3,
        na_pass = TRUE,
        brief = "Expect that |∆`wind_spd_mps`| < 10.3",
        preconditions = function(x) x |>
          group_by(meta_station_id) |>
          mutate(wind_spd_mps_delta = abs(wind_spd_mps - lag(wind_spd_mps)),
                 .after = wind_spd_mps) |>
          ungroup()
      ) |>

      # Temporal consistency ('persistence') checks:
      col_vals_equal(
        sol_rad_total_14,
        FALSE, #true means < 1 for the past 14 hours
        na_pass = TRUE,
        brief = "Expect that sol_rad_total should not be < 1 for more than 14 hours",
        preconditions = function(x) x |>
          group_by(meta_station_id) |>
          mutate(
            sol_rad_total_14 = slider::slide_lgl(
              sol_rad_total, ~all(.x < 1),
              .after = 14, #.after because arrange(desc(datetime))
              .complete = TRUE
            )
          ) |> ungroup()
      ) |>
      col_vals_equal(
        wind_spd_mps_14,
        FALSE, #true means < 1 for the past 14 hours
        na_pass = TRUE,
        brief = "Expect that wind_spd_mps should not be < 1 for more than 14 hours",
        preconditions = function(x) x |>
          group_by(meta_station_id) |>
          mutate(
            #slide_lgl turns an anonymous function into a sliding window function
            wind_spd_mps_14 = slider::slide_lgl(
              wind_spd_mps, ~all(.x < 1),
              .after = 14, #.after because arrange(desc(datetime))
              .complete = TRUE
            )
          ) |> ungroup()
      ) |>
      col_vals_equal(
        wind_vector_dir_14,
        FALSE, #true means < 1 for the past 14 hours
        na_pass = TRUE,
        brief = "Expect that wind_vector_dir should not be < 1 for more than 14 hours",
        preconditions = function(x) x |>
          group_by(meta_station_id) |>
          mutate(
            wind_vector_dir_14 = slider::slide_lgl(
              wind_vector_dir, ~all(.x < 1),
              .after = 14, #.after because arrange(desc(datetime))
              .complete = TRUE
            )
          ) |> ungroup()
      ) |>
      interrogate()

    get_agent_report(hourly_check, title = "Hourly Data Consistency Check")
  })
```

# Forecast-based validation

::: callout-warning
WORK IN PROGRESS\
Currently the same seasonal naïve model is fit to every variable and it is not always appropriate.
See model diagnostic plots with `tar_read(resid_daily)`.
:::

Mouse over the "TBL" column symbol to see which variable is associated with each row of the validation table.
A failed validation means the observed value fell outside of the 99% prediction interval of the forecast.

::: callout-note
A few variables are excluded from this validation because these timeseries models are inappropriate for them: `wind_vector_dir` is in polar coordinates, `sol_rad_total` and `precip_total_mm` because they are highly zero-inflated.
:::

```{r}
#| eval: false
#| column: body-outset
forecast_validation <- 
  create_agent(
  fc_daily,
  tbl_name = "Daily Measures",
  label = "Forecast-Based Validations",
  actions = al
) |> 
  col_vals_between(
    obs, vars(lower_99), vars(upper_99), segments = vars(varname)
    ) |> 
  interrogate()
get_agent_report(forecast_validation, title = "Forecast-based Validation (Daily Data)")
```

### Timeseries Plots

These show the last four weeks of data as a line, today's observed value as a blue point.
A forecast observation with 95% and 99% predictive intervals is shown in red.

```{r}
#| eval: false
library(ggdist)
varnames <- tar_read(forecast_qa_vars)
daily_long <- 
  daily |> 
  select(datetime, meta_station_name, meta_station_id, all_of(varnames)) |>
  pivot_longer(all_of(varnames), names_to = "varname")

daily_list <- daily_long |> group_by(varname) |> group_split()
fc_daily_list <- fc_daily |> group_by(varname) |> group_split()

# ts <- daily_list[[6]]
# fc <- fc_daily_list[[6]]

make_plot <- function(ts, fc) {
  ylab <- ts$varname |> unique()
  ts |> 
    filter(datetime > today() - weeks(4)) |> 
    #remove stations that don't have any data
    filter(meta_station_id %in% fc$meta_station_id) |> 
    ggplot(aes(x = datetime, y = value)) +
    geom_line() +
    geom_point(data = fc, aes(y = fc_mean), color = "red", shape = 1) +
    geom_point(data = fc, aes(y = obs), color = "blue") +
    geom_interval(data = fc, aes(ymin = lower_95, ymax = upper_95, y = fc_mean),
                  alpha = 0.3, color = "red") +
    geom_interval(data = fc, aes(ymin = lower_99, ymax = upper_99, y = fc_mean),
                  alpha = 0.3, color = "red") +
    labs(title = ylab, 
         y = ylab,
         x = "Date") +
    facet_wrap(~meta_station_id, ncol = 4, scales = "free_y") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
# make_plot(ts, fc)
```

```{r}
#| eval: false
#| fig-height: 8
#| fig-width: 8
#| warning: false
purrr::walk2(daily_list, fc_daily_list, \(.x, .y) make_plot(.x, .y) |> print())
```
